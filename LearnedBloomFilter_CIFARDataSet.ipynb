{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgC8UOfknS-q"
      },
      "outputs": [],
      "source": [
        "#Importing the libraries \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ms_Qu2RnXrC",
        "outputId": "0a450cf9-b8c6-44e7-d396-cfde920a20d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 7s 0us/step\n",
            "170508288/170498071 [==============================] - 7s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Loading the data \n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "# Partition into Test and Train Data \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCVEMoXroQc-",
        "outputId": "60ab40d2-268f-49bb-f8f8-5e4a2d92304b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjLqxBwlnZ7I"
      },
      "outputs": [],
      "source": [
        "# Reducing pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# flattening the label values\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1tyBFHuIfre",
        "outputId": "9b484476-31a7-42a9-8824-49d42601add5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDK0bkemflDd",
        "outputId": "20c2fc7a-cd19-43c7-8be7-bcc3e1b8772a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.23137255, 0.24313725, 0.24705882],\n",
              "        [0.16862745, 0.18039216, 0.17647059],\n",
              "        [0.19607843, 0.18823529, 0.16862745],\n",
              "        ...,\n",
              "        [0.61960784, 0.51764706, 0.42352941],\n",
              "        [0.59607843, 0.49019608, 0.4       ],\n",
              "        [0.58039216, 0.48627451, 0.40392157]],\n",
              "\n",
              "       [[0.0627451 , 0.07843137, 0.07843137],\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.07058824, 0.03137255, 0.        ],\n",
              "        ...,\n",
              "        [0.48235294, 0.34509804, 0.21568627],\n",
              "        [0.46666667, 0.3254902 , 0.19607843],\n",
              "        [0.47843137, 0.34117647, 0.22352941]],\n",
              "\n",
              "       [[0.09803922, 0.09411765, 0.08235294],\n",
              "        [0.0627451 , 0.02745098, 0.        ],\n",
              "        [0.19215686, 0.10588235, 0.03137255],\n",
              "        ...,\n",
              "        [0.4627451 , 0.32941176, 0.19607843],\n",
              "        [0.47058824, 0.32941176, 0.19607843],\n",
              "        [0.42745098, 0.28627451, 0.16470588]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.81568627, 0.66666667, 0.37647059],\n",
              "        [0.78823529, 0.6       , 0.13333333],\n",
              "        [0.77647059, 0.63137255, 0.10196078],\n",
              "        ...,\n",
              "        [0.62745098, 0.52156863, 0.2745098 ],\n",
              "        [0.21960784, 0.12156863, 0.02745098],\n",
              "        [0.20784314, 0.13333333, 0.07843137]],\n",
              "\n",
              "       [[0.70588235, 0.54509804, 0.37647059],\n",
              "        [0.67843137, 0.48235294, 0.16470588],\n",
              "        [0.72941176, 0.56470588, 0.11764706],\n",
              "        ...,\n",
              "        [0.72156863, 0.58039216, 0.36862745],\n",
              "        [0.38039216, 0.24313725, 0.13333333],\n",
              "        [0.3254902 , 0.20784314, 0.13333333]],\n",
              "\n",
              "       [[0.69411765, 0.56470588, 0.45490196],\n",
              "        [0.65882353, 0.50588235, 0.36862745],\n",
              "        [0.70196078, 0.55686275, 0.34117647],\n",
              "        ...,\n",
              "        [0.84705882, 0.72156863, 0.54901961],\n",
              "        [0.59215686, 0.4627451 , 0.32941176],\n",
              "        [0.48235294, 0.36078431, 0.28235294]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXr-ar5FniZa",
        "outputId": "3bd7e4c7-88a0-4fbf-8f66-944f3e8e34a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of classes: 10\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,397,226\n",
            "Trainable params: 2,396,330\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "\n",
        "# calculate total number of classes\n",
        "# for output layer\n",
        "print(\"number of classes:\", K)\n",
        "\n",
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=x_train[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTWBPThunkhJ"
      },
      "outputs": [],
      "source": [
        "# Model Compile\n",
        "model.compile(optimizer='adam',\n",
        "\t\t\tloss='sparse_categorical_crossentropy',\n",
        "\t\t\tmetrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiP32721nmOU",
        "outputId": "f988bdb4-8549-4a3d-d1e9-6412360d7576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 45s 21ms/step - loss: 1.2906 - accuracy: 0.5533 - val_loss: 1.0673 - val_accuracy: 0.6253\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8471 - accuracy: 0.7054 - val_loss: 0.8731 - val_accuracy: 0.7035\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.6903 - accuracy: 0.7604 - val_loss: 0.8154 - val_accuracy: 0.7268\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5805 - accuracy: 0.8002 - val_loss: 0.6740 - val_accuracy: 0.7729\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4933 - accuracy: 0.8309 - val_loss: 0.6211 - val_accuracy: 0.8016\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4125 - accuracy: 0.8580 - val_loss: 0.6081 - val_accuracy: 0.8039\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.3614 - accuracy: 0.8757 - val_loss: 0.5958 - val_accuracy: 0.8131\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.2995 - accuracy: 0.8974 - val_loss: 0.6254 - val_accuracy: 0.8025\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2594 - accuracy: 0.9097 - val_loss: 0.6196 - val_accuracy: 0.8118\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2256 - accuracy: 0.9219 - val_loss: 0.6735 - val_accuracy: 0.8137\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.1858 - accuracy: 0.9359 - val_loss: 0.6816 - val_accuracy: 0.8204\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.1777 - accuracy: 0.9397 - val_loss: 0.7257 - val_accuracy: 0.8169\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.1585 - accuracy: 0.9469 - val_loss: 0.7101 - val_accuracy: 0.8181\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1435 - accuracy: 0.9512 - val_loss: 0.7744 - val_accuracy: 0.8217\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.1322 - accuracy: 0.9555 - val_loss: 0.7173 - val_accuracy: 0.8303\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1278 - accuracy: 0.9572 - val_loss: 0.7292 - val_accuracy: 0.8169\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1186 - accuracy: 0.9606 - val_loss: 0.7121 - val_accuracy: 0.8264\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.1069 - accuracy: 0.9643 - val_loss: 0.7010 - val_accuracy: 0.8292\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.1014 - accuracy: 0.9664 - val_loss: 0.7123 - val_accuracy: 0.8257\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0950 - accuracy: 0.9688 - val_loss: 0.7686 - val_accuracy: 0.8263\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.0942 - accuracy: 0.9688 - val_loss: 0.7391 - val_accuracy: 0.8348\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.0853 - accuracy: 0.9723 - val_loss: 0.7695 - val_accuracy: 0.8316\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 33s 21ms/step - loss: 0.0860 - accuracy: 0.9721 - val_loss: 0.7484 - val_accuracy: 0.8287\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.0791 - accuracy: 0.9744 - val_loss: 0.6923 - val_accuracy: 0.8286\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0787 - accuracy: 0.9743 - val_loss: 0.7786 - val_accuracy: 0.8379\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0735 - accuracy: 0.9760 - val_loss: 0.7625 - val_accuracy: 0.8307\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 0.7708 - val_accuracy: 0.8414\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.7526 - val_accuracy: 0.8374\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.0634 - accuracy: 0.9790 - val_loss: 0.8688 - val_accuracy: 0.8204\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 0.0634 - accuracy: 0.9791 - val_loss: 0.8293 - val_accuracy: 0.8382\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0628 - accuracy: 0.9793 - val_loss: 0.8322 - val_accuracy: 0.8361\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 0.7311 - val_accuracy: 0.8391\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0585 - accuracy: 0.9808 - val_loss: 0.8335 - val_accuracy: 0.8360\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.7934 - val_accuracy: 0.8364\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.8084 - val_accuracy: 0.8341\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0492 - accuracy: 0.9834 - val_loss: 0.8657 - val_accuracy: 0.8389\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0528 - accuracy: 0.9827 - val_loss: 0.8304 - val_accuracy: 0.8466\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0478 - accuracy: 0.9844 - val_loss: 0.8786 - val_accuracy: 0.8364\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.8643 - val_accuracy: 0.8322\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.7609 - val_accuracy: 0.8378\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0453 - accuracy: 0.9855 - val_loss: 0.7718 - val_accuracy: 0.8412\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.8389 - val_accuracy: 0.8379\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.8458 - val_accuracy: 0.8429\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 0.8935 - val_accuracy: 0.8363\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.8349 - val_accuracy: 0.8405\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 0.8417 - val_accuracy: 0.8412\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.8745 - val_accuracy: 0.8401\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 0.8562 - val_accuracy: 0.8360\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0417 - accuracy: 0.9863 - val_loss: 0.8879 - val_accuracy: 0.8341\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.9431 - val_accuracy: 0.8387\n"
          ]
        }
      ],
      "source": [
        "# Model Fitting\n",
        "r = model.fit(\n",
        "x_train, y_train, validation_data=(x_test, y_test), epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-8SAl5miogj",
        "outputId": "f5006673-5ce7-43cf-d3fd-2e5a53b98531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.5468 - accuracy: 0.8272 - val_loss: 0.5005 - val_accuracy: 0.8346\n",
            "Epoch 2/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.4331 - accuracy: 0.8575 - val_loss: 0.4748 - val_accuracy: 0.8437\n",
            "Epoch 3/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3999 - accuracy: 0.8680 - val_loss: 0.4528 - val_accuracy: 0.8532\n",
            "Epoch 4/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3768 - accuracy: 0.8753 - val_loss: 0.4507 - val_accuracy: 0.8485\n",
            "Epoch 5/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3644 - accuracy: 0.8778 - val_loss: 0.4760 - val_accuracy: 0.8437\n",
            "Epoch 6/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3497 - accuracy: 0.8812 - val_loss: 0.4751 - val_accuracy: 0.8478\n",
            "Epoch 7/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3326 - accuracy: 0.8871 - val_loss: 0.4313 - val_accuracy: 0.8541\n",
            "Epoch 8/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3264 - accuracy: 0.8908 - val_loss: 0.4165 - val_accuracy: 0.8641\n",
            "Epoch 9/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.3100 - accuracy: 0.8960 - val_loss: 0.4684 - val_accuracy: 0.8535\n",
            "Epoch 10/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.3084 - accuracy: 0.8951 - val_loss: 0.4523 - val_accuracy: 0.8546\n",
            "Epoch 11/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.2976 - accuracy: 0.8996 - val_loss: 0.4294 - val_accuracy: 0.8591\n",
            "Epoch 12/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.2846 - accuracy: 0.9045 - val_loss: 0.4950 - val_accuracy: 0.8495\n",
            "Epoch 13/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2818 - accuracy: 0.9042 - val_loss: 0.4310 - val_accuracy: 0.8624\n",
            "Epoch 14/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2750 - accuracy: 0.9074 - val_loss: 0.4196 - val_accuracy: 0.8696\n",
            "Epoch 15/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.2654 - accuracy: 0.9090 - val_loss: 0.4283 - val_accuracy: 0.8672\n",
            "Epoch 16/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.2620 - accuracy: 0.9110 - val_loss: 0.4048 - val_accuracy: 0.8695\n",
            "Epoch 17/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.2560 - accuracy: 0.9136 - val_loss: 0.4192 - val_accuracy: 0.8706\n",
            "Epoch 18/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2549 - accuracy: 0.9141 - val_loss: 0.4477 - val_accuracy: 0.8650\n",
            "Epoch 19/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2457 - accuracy: 0.9170 - val_loss: 0.4230 - val_accuracy: 0.8711\n",
            "Epoch 20/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2401 - accuracy: 0.9191 - val_loss: 0.4155 - val_accuracy: 0.8655\n",
            "Epoch 21/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.2374 - accuracy: 0.9192 - val_loss: 0.4031 - val_accuracy: 0.8744\n",
            "Epoch 22/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.2310 - accuracy: 0.9212 - val_loss: 0.4023 - val_accuracy: 0.8751\n",
            "Epoch 23/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2282 - accuracy: 0.9225 - val_loss: 0.4228 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.2213 - accuracy: 0.9238 - val_loss: 0.4485 - val_accuracy: 0.8704\n",
            "Epoch 25/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2202 - accuracy: 0.9244 - val_loss: 0.4114 - val_accuracy: 0.8763\n",
            "Epoch 26/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.2225 - accuracy: 0.9249 - val_loss: 0.4607 - val_accuracy: 0.8656\n",
            "Epoch 27/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.2117 - accuracy: 0.9282 - val_loss: 0.4169 - val_accuracy: 0.8707\n",
            "Epoch 28/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.2146 - accuracy: 0.9283 - val_loss: 0.4008 - val_accuracy: 0.8761\n",
            "Epoch 29/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.2064 - accuracy: 0.9297 - val_loss: 0.4558 - val_accuracy: 0.8644\n",
            "Epoch 30/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.2040 - accuracy: 0.9315 - val_loss: 0.4403 - val_accuracy: 0.8730\n",
            "Epoch 31/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.1978 - accuracy: 0.9315 - val_loss: 0.4528 - val_accuracy: 0.8738\n",
            "Epoch 32/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.1970 - accuracy: 0.9337 - val_loss: 0.4217 - val_accuracy: 0.8778\n",
            "Epoch 33/50\n",
            "1562/1562 [==============================] - 56s 36ms/step - loss: 0.1968 - accuracy: 0.9345 - val_loss: 0.4316 - val_accuracy: 0.8764\n",
            "Epoch 34/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.1966 - accuracy: 0.9337 - val_loss: 0.4108 - val_accuracy: 0.8796\n",
            "Epoch 35/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.1970 - accuracy: 0.9334 - val_loss: 0.4099 - val_accuracy: 0.8791\n",
            "Epoch 36/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.1859 - accuracy: 0.9373 - val_loss: 0.4664 - val_accuracy: 0.8769\n",
            "Epoch 37/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1867 - accuracy: 0.9359 - val_loss: 0.4750 - val_accuracy: 0.8685\n",
            "Epoch 38/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1857 - accuracy: 0.9365 - val_loss: 0.4300 - val_accuracy: 0.8798\n",
            "Epoch 39/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1853 - accuracy: 0.9365 - val_loss: 0.3930 - val_accuracy: 0.8807\n",
            "Epoch 40/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1753 - accuracy: 0.9407 - val_loss: 0.4033 - val_accuracy: 0.8854\n",
            "Epoch 41/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1770 - accuracy: 0.9390 - val_loss: 0.4206 - val_accuracy: 0.8771\n",
            "Epoch 42/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.1758 - accuracy: 0.9401 - val_loss: 0.4672 - val_accuracy: 0.8714\n",
            "Epoch 43/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1776 - accuracy: 0.9406 - val_loss: 0.4227 - val_accuracy: 0.8801\n",
            "Epoch 44/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1736 - accuracy: 0.9420 - val_loss: 0.4513 - val_accuracy: 0.8787\n",
            "Epoch 45/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.1701 - accuracy: 0.9428 - val_loss: 0.4356 - val_accuracy: 0.8799\n",
            "Epoch 46/50\n",
            "1562/1562 [==============================] - 55s 35ms/step - loss: 0.1722 - accuracy: 0.9422 - val_loss: 0.4251 - val_accuracy: 0.8883\n",
            "Epoch 47/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.1653 - accuracy: 0.9445 - val_loss: 0.4557 - val_accuracy: 0.8770\n",
            "Epoch 48/50\n",
            "1562/1562 [==============================] - 54s 35ms/step - loss: 0.1642 - accuracy: 0.9453 - val_loss: 0.4536 - val_accuracy: 0.8778\n",
            "Epoch 49/50\n",
            "1562/1562 [==============================] - 54s 34ms/step - loss: 0.1646 - accuracy: 0.9445 - val_loss: 0.4393 - val_accuracy: 0.8836\n",
            "Epoch 50/50\n",
            "1562/1562 [==============================] - 53s 34ms/step - loss: 0.1677 - accuracy: 0.9451 - val_loss: 0.4604 - val_accuracy: 0.8746\n"
          ]
        }
      ],
      "source": [
        "# Fit with data augmentation\n",
        "batch_size = 32\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "r = model.fit(train_generator, validation_data=(x_test, y_test),\n",
        "\t\t\tsteps_per_epoch=steps_per_epoch, epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VDe93CGxViW"
      },
      "outputs": [],
      "source": [
        "# label mapping\n",
        "\n",
        "labels = ''''''.split()\n",
        "\n",
        "# select the image from our test dataset\n",
        "image_number = 0\n",
        "\n",
        "# load the image in an array\n",
        "n = np.array(x_train)\n",
        "\n",
        "p=[]\n",
        "# reshape it\n",
        "for i in range(len(n)):\n",
        "  p.append(n[i].reshape(1, 32, 32, 3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzXNm5CJmXCX",
        "outputId": "df3c90d1-121e-4b1c-9fad-b3c4b34bb88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JHmcmzh9cPP"
      },
      "outputs": [],
      "source": [
        "predicted_label=[]\n",
        "for i in range(50000):\n",
        " predicted_label.append(model.predict(p[i]).argmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9D1hPHqW9e2",
        "outputId": "f696cfa1-fbdd-4c53-8748-c9dc356fbbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bloom-filter\n",
            "  Downloading bloom_filter-1.3.3-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: bloom-filter\n",
            "Successfully installed bloom-filter-1.3.3\n"
          ]
        }
      ],
      "source": [
        "%pip install bloom-filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNZV7qPLXhu_"
      },
      "outputs": [],
      "source": [
        "#Traditional Bloom Filter \n",
        "from bloom_filter import BloomFilter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBj9jDwqzN3D"
      },
      "outputs": [],
      "source": [
        " def Train_overflow(bloom,train_features,y_new_train,preds,tau):\n",
        "    X_train=train_features\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i]>tau:\n",
        "              if y_new_train[i] ==1:\n",
        "                  bloom.add(str(X_train[i]))\n",
        "    return bloom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrJwFcjtqDHy"
      },
      "outputs": [],
      "source": [
        "def binarized(Y_train):\n",
        "  y=[]\n",
        "  for i in range(len(Y_train)):\n",
        "        if(Y_train[i]<=4):\n",
        "          y.append(1)\n",
        "        else:\n",
        "          y.append(0)\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fVb9vA7qxKK"
      },
      "outputs": [],
      "source": [
        "tau=4\n",
        "bloom_traditional = BloomFilter(max_elements=25000)\n",
        "y_new_train=binarized(y_train)\n",
        "\n",
        "bloom_overflow=Train_overflow(bloom_traditional,x_train,y_new_train,predicted_label,tau)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F96ROQs0rVYd"
      },
      "outputs": [],
      "source": [
        "# loading the image in an array\n",
        "n = np.array(x_test)\n",
        "p=[]\n",
        "# reshape it\n",
        "for i in range(len(n)):\n",
        "  p.append(n[i].reshape(1, 32, 32, 3))\n",
        "\n",
        "predicted_tst=[]\n",
        "for i in range(len(x_test)):\n",
        "  predicted_tst.append(model.predict(p[i]).argmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_DC0zkCtlcZ"
      },
      "outputs": [],
      "source": [
        "pred_new_test=binarized(predicted_tst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ3X89zl2vWk",
        "outputId": "4fa7b8da-d237-4579-c24e-0b3cd425b4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1254\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for i in range(len(predicted_tst)):\n",
        "   if predicted_tst[i]!=y_test[i]:\n",
        "     count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3euN1Igtink"
      },
      "outputs": [],
      "source": [
        "def positive_negative(X,Y,tau,predicted_tst):\n",
        "    keys=[]\n",
        "    non_keys=[]\n",
        "    pred_keys=[]\n",
        "    pred_non_keys=[]\n",
        "    actual_for_keys=[]\n",
        "    actual_for_non_keys=[]\n",
        "    print(\"positive\",len(Y))\n",
        "    count1=0\n",
        "    count2=0\n",
        "    for i in range(len(predicted_tst)):\n",
        "     if predicted_tst[i]<=tau:\n",
        "        keys.append(X[i])\n",
        "        pred_keys.append(1)\n",
        "        if predicted_tst[i]!=Y[i]:\n",
        "           actual_for_keys.append(Y[i])\n",
        "           count1+=1\n",
        "           #print(count1)\n",
        "     elif str(X[i]) in bloom_overflow:\n",
        "           keys.append(X[i])\n",
        "           actual_for_keys.append([i,Y[i]])\n",
        "           count2+=1\n",
        "     else:\n",
        "          non_keys.append(X[i])\n",
        "          pred_non_keys.append(0)\n",
        "          actual_for_non_keys.append([i,Y[i]])\n",
        "           #print(count2)\n",
        "    return keys,non_keys,pred_keys,pred_non_keys,actual_for_keys,actual_for_non_keys,count1,count2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCMy0HR_5cIQ"
      },
      "outputs": [],
      "source": [
        "def Test_BF_FNR(model,bloom_overflow,non_keys,tau,prediction):\n",
        "      output1=[]\n",
        "      FN=0\n",
        "      for i in range(len(non_keys)):\n",
        "          if str(non_keys[i]) in bloom_overflow:\n",
        "              output1.append(1)\n",
        "              FN+=1\n",
        "          else:\n",
        "              output1.append(0)\n",
        "      \n",
        "      return np.array(output1),FN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSHulDSqkB0c",
        "outputId": "6ec6ffe3-6bea-4d4e-e695-1b82028bb63e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive 10000\n"
          ]
        }
      ],
      "source": [
        "tau=4\n",
        "keys,non_keys,pred_keys,pred_nonkeys,actual_for_keys,actual_for_non_keys,count1,count2=positive_negative(x_test,y_test,tau,predicted_tst)\n",
        "keys=np.array(keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOnxBk0s39uT",
        "outputId": "935f4c2c-9648-481c-eed6-a954c4cbcfeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FNR 0.1459534698747266 FPR 0.0\n"
          ]
        }
      ],
      "source": [
        "print(\"FNR\",count1/len(keys),\"FPR\",count2/len(non_keys))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h724YdbKUlTe"
      },
      "outputs": [],
      "source": [
        "def Test_BF(bloom1, test_data):\n",
        "  y_pred_bloom = []\n",
        "  for i in test_data:\n",
        "    if str(i) in bloom1:\n",
        "      y_pred_bloom.append(1)\n",
        "    else:\n",
        "      y_pred_bloom.append(0)\n",
        "  y_pred_bloom = np.array(y_pred_bloom)\n",
        "  return y_pred_bloom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bOpGdC6nfu4"
      },
      "outputs": [],
      "source": [
        "#creating traditional bloom filter\n",
        "bloom4 =BloomFilter(max_elements=325000)\n",
        "dataset=[]\n",
        "for i in range(len(x_train)):\n",
        "   dataset.append([x_train[i],y_new_train[i]]) \n",
        "for data_point in dataset:\n",
        "        if data_point[1]==1:\n",
        "            bloom4.add(data_point[0].all()) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_bloom_tr=Test_BF(bloom4,x_train)"
      ],
      "metadata": {
        "id": "YJZ0RjE265xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPTCluKQn6OW",
        "outputId": "7bbac690-4850-4240-ba4a-9b7d03cfe75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_new_train,Y_pred_bloom_tr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZgLx-Wn4Yn"
      },
      "outputs": [],
      "source": [
        "Y_pred_bloom=Test_BF(bloom4,x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4doyU3-ioMX9",
        "outputId": "a146c60d-4251-4b4d-d0b0-83e003495d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score(Y_pred_bloom,y_new_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zU9sjHypj07",
        "outputId": "c08f2028-d968-48c0-ee6b-5db6752716ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TN 5000\n",
            "TP 5000\n"
          ]
        }
      ],
      "source": [
        "#Calculating true negatives\n",
        "TN=0\n",
        "for i in range(len(y_new_test)):\n",
        "  if y_new_test[i] == 0:\n",
        "       TN+=1\n",
        "print(\"TN\",TN)\n",
        "#Calculating true positives\n",
        "TP=0\n",
        "for i in range(len(y_new_test)):\n",
        "  if y_new_test[i] == 1:\n",
        "       TP+=1\n",
        "print(\"TP\",TP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMdctuQoqBuS",
        "outputId": "6f2a491c-8ad5-42c0-eaa9-b8294d716dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zero false negative rate\n",
            "0\n",
            "0 0.0\n"
          ]
        }
      ],
      "source": [
        "FN=Test_FNR_bloom(Y_pred_bloom,y_new_test)\n",
        "if(FN==0):\n",
        "  print(\"zero false negative rate\")\n",
        "else:\n",
        "  print(FN,FN/(FN+TP))\n",
        "FP=Test_FPR_bloom(Y_pred_bloom,y_new_test)\n",
        "print(FP,FP/(FP+TN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySgVWIcWp6e_"
      },
      "outputs": [],
      "source": [
        "def Test_FPR_bloom(prediction,y_new_test):\n",
        "      output1=[]\n",
        "      count1=0\n",
        "      for i in range(len(x_test)):\n",
        "             if(y_new_test[i]==0 and prediction[i]==1):\n",
        "               count1+=1\n",
        "      print(count1)\n",
        "      return count1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqDQoiF4p-6y"
      },
      "outputs": [],
      "source": [
        "def Test_FNR_bloom(y_pred,y_new_test):\n",
        "    count1=0\n",
        "    for i in range(len(y_new_test)):\n",
        "          if y_new_test[i] == 1 and y_pred[i]==0:\n",
        "             count1+=1\n",
        "\n",
        "    if count1==TN:\n",
        "        return 0\n",
        "    else:\n",
        "        return TN-count1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Learned_CIFAR10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}